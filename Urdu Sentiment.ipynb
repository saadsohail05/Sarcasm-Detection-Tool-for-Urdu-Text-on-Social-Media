{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Sentiment Analysis Tool for Urdu Text on Social Media Platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>نہیں پائین 😎</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           urdu_text  is_sarcastic\n",
       "0  🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...           1.0\n",
       "1  چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...           1.0\n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...           0.0\n",
       "3                                       نہیں پائین 😎           0.0\n",
       "4   `` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...           1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('urdu_sarcastic_dataset.csv')\n",
    "df.head()\n",
    "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7'], inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a list of stopwords\n",
    "with open(\"stopwords-ur.txt\", 'r', encoding='utf-8') as file:\n",
    "        stopwords_from_file = file.read().splitlines()\n",
    "\n",
    "stopdf=pd.read_csv(\"urdu_stopwords.csv\",encoding='utf-8')\n",
    "stopwords_from_csv = stopdf[\"stopword\"].tolist()\n",
    "\n",
    "# Additional stopwords\n",
    "stop_words = set(\"\"\"\n",
    "\n",
    " آ آئی آئیں آئے آتا آتی آتے آداب آدھ آدھا آدھی آدھے آس آمدید آنا آنسہ آنی آنے\n",
    " آپ آگے آہ آہا آیا اب ابھی ابے اتوار ارب اربویں ارے اس اسکا اسکی اسکے اسی اسے اف\n",
    " افوہ الاول البتہ الثانی الحرام السلام الف المکرم ان اندر انکا انکی انکے انہوں انہی انہیں اوئے اور\n",
    " اوپر اوہو اپ اپنا اپنوں اپنی اپنے اپنےآپ اکبر اکثر اگر اگرچہ اگست اہاہا ایسا ایسی ایسے ایک بائیں\n",
    " بار بارے بالکل باوجود باہر بج بجے بخیر برسات بشرطیکہ بعد بعض بغیر بلکہ بن بنا بناؤ بند\n",
    " بڑی بھر بھریں بھی بہار بہت بہتر بیگم تاکہ تاہم تب تجھ تجھی تجھے ترا تری تلک تم تمام\n",
    " تمہارا تمہاروں تمہاری تمہارے تمہیں تو تک تھا تھی تھیں تھے تہائی تیرا تیری تیرے تین جا جاؤ\n",
    " جائیں جائے جاتا جاتی جاتے جانی جانے جب جبکہ جدھر جس جسے جن جناب جنہوں جنہیں جو جہاں جی\n",
    " جیسا جیسوں جیسی جیسے جیٹھ حالانکہ حالاں حصہ حضرت خاطر خالی خدا خزاں خواہ خوب خود دائیں درمیان\n",
    " دریں دو دوران دوسرا دوسروں دوسری دوشنبہ دوں دکھائیں دگنا دی دیئے دیا دیتا دیتی دیتے دیر دینا دینی\n",
    " دینے دیکھو دیں دیے دے ذریعے رکھا رکھتا رکھتی رکھتے رکھنا رکھنی رکھنے رکھو رکھی رکھے رہ رہا\n",
    " رہتا رہتی رہتے رہنا رہنی رہنے رہو رہی رہیں رہے ساتھ سامنے ساڑھے سب سبھی سراسر سلام سمیت سوا\n",
    " سوائے سکا سکتا سکتے سہ سہی سی سے شام شاید شکریہ صاحب صاحبہ صرف ضرور طرح طرف طور\n",
    " علاوہ عین فروری فقط فلاں فی قبل قطا لئے لائی لائے لاتا لاتی لاتے لانا لانی لانے لایا لو\n",
    " لوجی لوگوں لگ لگا لگتا لگتی لگی لگیں لگے لہذا لی لیا لیتا لیتی لیتے لیکن لیں لیے\n",
    " لے ماسوا مت مجھ مجھی مجھے محترم محترمہ محترمی محض مرا مرحبا مری مرے مزید مس مسز مسٹر مطابق\n",
    " مطلق مل منٹ منٹوں مکرمی مگر مگھر مہربانی میرا میروں میری میرے میں نا نزدیک نما نو نومبر\n",
    " نہ نہیں نیز نیچے نے و وار واسطے واقعی والا والوں والی والے واہ وجہ ورنہ وعلیکم وغیرہ ولے\n",
    " وگرنہ وہ وہاں وہی وہیں ویسا ویسے ویں پاس پایا پر پس پلیز پون پونا پونی پونے پھاگن\n",
    " پھر پہ پہر پہلا پہلی پہلے پیر پیچھے چاہئے چاہتے چاہیئے چاہے چلا چلو چلیں چلے چناچہ چند چونکہ\n",
    " چوگنی چکی چکیں چکے چہارشنبہ چیت ڈالنا ڈالنی ڈالنے ڈالے کئے کا کاتک کاش کب کبھی کدھر کر\n",
    " کرتا کرتی کرتے کرم کرنا کرنے کرو کریں کرے کس کسی کسے کل کم کن کنہیں کو کوئی کون\n",
    " کونسا کونسے کچھ کہ کہا کہاں کہہ کہی کہیں کہے کی کیا کیسا کیسے کیونکر کیونکہ کیوں کیے\n",
    " کے گئی گئے گا گرما گرمی گنا گو گویا گھنٹا گھنٹوں گھنٹے گی گیا ہائیں ہائے ہاڑ ہاں ہر\n",
    " ہرچند ہرگز ہزار ہفتہ ہم ہمارا ہماری ہمارے ہمی ہمیں ہو ہوئی ہوئیں ہوئے ہوا ہوبہو ہوتا ہوتی\n",
    " ہوتیں ہوتے ہونا ہونگے ہونی ہونے ہوں ہی ہیلو ہیں ہے یا یات یعنی یک یہ یہاں یہی یہیں\n",
    "\n",
    "\n",
    "\"\"\".split())\n",
    "\n",
    "final_stopwords = set(stopwords_from_file + stopwords_from_csv)\n",
    "final_stopwords.update(stop_words) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment words found in stopwords: ['نہیں']\n"
     ]
    }
   ],
   "source": [
    "# checking if stopwords contain any sentiment words\n",
    "urdu_sentiment_words = [\"نہیں\", \"برا\", \"خوش\", \"اچھا\"]\n",
    "found=[]\n",
    "for stopword in final_stopwords:\n",
    "    if stopword in urdu_sentiment_words:\n",
    "        found.append(stopword)\n",
    "\n",
    "if found:\n",
    "    print(\"Sentiment words found in stopwords:\", found)\n",
    "    final_stopwords.update(found)\n",
    "else:\n",
    "    print(\"No sentiment words found in stopwords.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "print(df[\"urdu_text\"].isnull().sum())\n",
    "df.dropna(subset=['urdu_text', 'is_sarcastic'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numbers Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(x):\n",
    "    return re.sub(r'\\d+', '', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"urdu_text\"]=df[\"urdu_text\"].apply(remove_numbers)\n",
    "# print(df[\"urdu_text\"][12])\n",
    "# print(remove_numbers(df[\"urdu_text\"][12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emojis Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"  \n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"  \n",
    "        u\"\\U000024C2-\\U0001F251\"  \n",
    "        u\"\\U0001F900-\\U0001F9FF\"  # additional emojis\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"urdu_text\"]=df[\"urdu_text\"].apply(remove_emoji)\n",
    "# print(df[\"urdu_text\"][0])\n",
    "# print(remove_emoji(df[\"urdu_text\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashtag and Mentions Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hash_sign(text):\n",
    "    return re.sub(r'#', '', text)  \n",
    "\n",
    "def remove_mentions(text):\n",
    "    return re.sub(r'@\\w+', '', text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " جب کتے زیادہ بھونکنے لگے تو ان کے آگے رکھنے کیلئے ہڈیوں کی تعداد بڑھا دواقوال کرائم منسٹر شوباز شریف برادر گوالمنڈیلا لندن والے سے اقتباسامپورٹڈ_حکومت_نامنظور امپورٹڈ_عدالتیں_نامنظور\n",
      " بغض کو کیسے سائیڈ پہ رکھیں؟ ابو جہل کو بھلا جہنم میں تنہا چھوڑ دیں۔ توڑ ساتھ نبھائیں گے\n",
      "Sarcasm\n",
      " جب کتے زیادہ بھونکنے لگے تو ان کے آگے رکھنے کیلئے ہڈیوں کی تعداد بڑھا دواقوال کرائم منسٹر شوباز شریف برادر گوالمنڈیلا لندن والے سے اقتباسامپورٹڈ_حکومت_نامنظور امپورٹڈ_عدالتیں_نامنظور\n",
      " بغض کو کیسے سائیڈ پہ رکھیں؟ ابو جہل کو بھلا جہنم میں تنہا چھوڑ دیں۔ توڑ ساتھ نبھائیں گے\n",
      "Sarcasm\n"
     ]
    }
   ],
   "source": [
    "df[\"urdu_text\"]=df[\"urdu_text\"].apply(remove_hash_sign)\n",
    "print(df[\"urdu_text\"][5277])\n",
    "print(df[\"urdu_text\"][5612])\n",
    "df[\"urdu_text\"]=df[\"urdu_text\"].apply(remove_mentions)\n",
    "print(df[\"urdu_text\"][5277])\n",
    "print(df[\"urdu_text\"][5612])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URLs Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"urdu_text\"]=df[\"urdu_text\"].apply(remove_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove English Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_english_words(text):\n",
    "    return re.sub(r'\\b[a-zA-Z]+\\b', '', text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"urdu_text\"]=df[\"urdu_text\"].apply(remove_english_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "urdu_diacritics  = ['ِ', 'ٰ', 'ُ', 'ٍ', 'ً', 'َ']\n",
    "\n",
    "def remove_diacritics(text):\n",
    "    for letter in text:\n",
    "    \n",
    "        if letter in urdu_diacritics:\n",
    "            text = text.replace(letter, '')\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"urdu_text\"]=df[\"urdu_text\"].apply(remove_diacritics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    # Defining the punctuation characters to remove\n",
    "    punct = '؛۔٫٪+=@#!؟،)(}{\\'\"‘’“”``'\n",
    "    return text.translate(str.maketrans('', '', punct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"urdu_text\"]=df[\"urdu_text\"].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word not in final_stopwords:  \n",
    "            new_text.append(word)  \n",
    "    return \" \".join(new_text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بہترین کتاب\n"
     ]
    }
   ],
   "source": [
    "cleaned_text = remove_stopwords(\"یہ ایک بہترین کتاب ہے\")\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>لینے شادی فسادن کوجی چاہیے</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کامران خان دن بھریہ زمہ داری لگائی اپوزیشن کرد...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>پائین</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` مراد علی شاہ بھیس ڈی ایس '' حامد میر</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>قابل اعتبار قاتل اعتبار</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>انساں تھکا سوچوں سفر ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>حامد میر ویلڈن</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>یار وچارہ ویلا ہوندا آرے ہویا تسی تے پکے نجومی...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>سمجھتے سارا پاکستان بیوقوف ھے</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           urdu_text  is_sarcastic\n",
       "0                         لینے شادی فسادن کوجی چاہیے           1.0\n",
       "1         چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں           1.0\n",
       "2  کامران خان دن بھریہ زمہ داری لگائی اپوزیشن کرد...           0.0\n",
       "3                                              پائین           0.0\n",
       "4            `` مراد علی شاہ بھیس ڈی ایس '' حامد میر           1.0\n",
       "5                            قابل اعتبار قاتل اعتبار           1.0\n",
       "6                           انساں تھکا سوچوں سفر ...           0.0\n",
       "7                                     حامد میر ویلڈن           0.0\n",
       "8  یار وچارہ ویلا ہوندا آرے ہویا تسی تے پکے نجومی...           1.0\n",
       "9                      سمجھتے سارا پاکستان بیوقوف ھے           1.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['urdu_text'] = df['urdu_text'].apply(remove_stopwords)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Short Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_short_posts(text):\n",
    "    words = text.split()\n",
    "    return len(words) >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['urdu_text'].apply(filter_short_posts)\n",
    "df = df[mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>لینے شادی فسادن کوجی چاہیے</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کامران خان دن بھریہ زمہ داری لگائی اپوزیشن کرد...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>مراد علی شاہ بھیس ڈی ایس  حامد میر</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>قابل اعتبار قاتل اعتبار</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>انساں تھکا سوچوں سفر ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>حامد میر ویلڈن</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>یار وچارہ ویلا ہوندا آرے ہویا تسی تے پکے نجومی...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>سمجھتے سارا پاکستان بیوقوف ھے</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>تسی لڑاںٔی کروانی ساڈی</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>پائن دوبارہ فالو کرئیے..</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>کتنی مہنگائی الو دوسو روپے درجن کدو روپے گز</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>عشق راس آۓ زخم کھاٶ مسکراٶ</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>خاتم_النبیین_محمد سورة المزمل ترجمہ اللہ راہ ل...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>بس بیچارے بیویاں ہیے تیسری ٹرائ</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            urdu_text  is_sarcastic\n",
       "0                          لینے شادی فسادن کوجی چاہیے           1.0\n",
       "1          چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں           1.0\n",
       "2   کامران خان دن بھریہ زمہ داری لگائی اپوزیشن کرد...           0.0\n",
       "3                  مراد علی شاہ بھیس ڈی ایس  حامد میر           1.0\n",
       "4                             قابل اعتبار قاتل اعتبار           1.0\n",
       "5                            انساں تھکا سوچوں سفر ...           0.0\n",
       "6                                      حامد میر ویلڈن           0.0\n",
       "7   یار وچارہ ویلا ہوندا آرے ہویا تسی تے پکے نجومی...           1.0\n",
       "8                       سمجھتے سارا پاکستان بیوقوف ھے           1.0\n",
       "9                              تسی لڑاںٔی کروانی ساڈی           0.0\n",
       "10                           پائن دوبارہ فالو کرئیے..           0.0\n",
       "11        کتنی مہنگائی الو دوسو روپے درجن کدو روپے گز           1.0\n",
       "12                         عشق راس آۓ زخم کھاٶ مسکراٶ           1.0\n",
       "13  خاتم_النبیین_محمد سورة المزمل ترجمہ اللہ راہ ل...           0.0\n",
       "14                    بس بیچارے بیویاں ہیے تیسری ٹرائ           1.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
