{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Sentiment Analysis Tool for Urdu Text on Social Media Platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†Û...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           urdu_text  is_sarcastic\n",
       "0  ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†Û...           1.0\n",
       "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...           1.0\n",
       "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...           0.0\n",
       "3                                       Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜           0.0\n",
       "4   `` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ...           1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('urdu_sarcastic_dataset.csv')\n",
    "df.head()\n",
    "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7'], inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a list of stopwords\n",
    "with open(\"stopwords-ur.txt\", 'r', encoding='utf-8') as file:\n",
    "        stopwords_from_file = file.read().splitlines()\n",
    "\n",
    "stopdf=pd.read_csv(\"urdu_stopwords.csv\",encoding='utf-8')\n",
    "stopwords_from_csv = stopdf[\"stopword\"].tolist()\n",
    "\n",
    "# Additional stopwords\n",
    "stop_words = set(\"\"\"\n",
    "\n",
    " Ø¢ Ø¢Ø¦ÛŒ Ø¢Ø¦ÛŒÚº Ø¢Ø¦Û’ Ø¢ØªØ§ Ø¢ØªÛŒ Ø¢ØªÛ’ Ø¢Ø¯Ø§Ø¨ Ø¢Ø¯Ú¾ Ø¢Ø¯Ú¾Ø§ Ø¢Ø¯Ú¾ÛŒ Ø¢Ø¯Ú¾Û’ Ø¢Ø³ Ø¢Ù…Ø¯ÛŒØ¯ Ø¢Ù†Ø§ Ø¢Ù†Ø³Û Ø¢Ù†ÛŒ Ø¢Ù†Û’\n",
    " Ø¢Ù¾ Ø¢Ú¯Û’ Ø¢Û Ø¢ÛØ§ Ø¢ÛŒØ§ Ø§Ø¨ Ø§Ø¨Ú¾ÛŒ Ø§Ø¨Û’ Ø§ØªÙˆØ§Ø± Ø§Ø±Ø¨ Ø§Ø±Ø¨ÙˆÛŒÚº Ø§Ø±Û’ Ø§Ø³ Ø§Ø³Ú©Ø§ Ø§Ø³Ú©ÛŒ Ø§Ø³Ú©Û’ Ø§Ø³ÛŒ Ø§Ø³Û’ Ø§Ù\n",
    " Ø§ÙÙˆÛ Ø§Ù„Ø§ÙˆÙ„ Ø§Ù„Ø¨ØªÛ Ø§Ù„Ø«Ø§Ù†ÛŒ Ø§Ù„Ø­Ø±Ø§Ù… Ø§Ù„Ø³Ù„Ø§Ù… Ø§Ù„Ù Ø§Ù„Ù…Ú©Ø±Ù… Ø§Ù† Ø§Ù†Ø¯Ø± Ø§Ù†Ú©Ø§ Ø§Ù†Ú©ÛŒ Ø§Ù†Ú©Û’ Ø§Ù†ÛÙˆÚº Ø§Ù†ÛÛŒ Ø§Ù†ÛÛŒÚº Ø§ÙˆØ¦Û’ Ø§ÙˆØ±\n",
    " Ø§ÙˆÙ¾Ø± Ø§ÙˆÛÙˆ Ø§Ù¾ Ø§Ù¾Ù†Ø§ Ø§Ù¾Ù†ÙˆÚº Ø§Ù¾Ù†ÛŒ Ø§Ù¾Ù†Û’ Ø§Ù¾Ù†Û’Ø¢Ù¾ Ø§Ú©Ø¨Ø± Ø§Ú©Ø«Ø± Ø§Ú¯Ø± Ø§Ú¯Ø±Ú†Û Ø§Ú¯Ø³Øª Ø§ÛØ§ÛØ§ Ø§ÛŒØ³Ø§ Ø§ÛŒØ³ÛŒ Ø§ÛŒØ³Û’ Ø§ÛŒÚ© Ø¨Ø§Ø¦ÛŒÚº\n",
    " Ø¨Ø§Ø± Ø¨Ø§Ø±Û’ Ø¨Ø§Ù„Ú©Ù„ Ø¨Ø§ÙˆØ¬ÙˆØ¯ Ø¨Ø§ÛØ± Ø¨Ø¬ Ø¨Ø¬Û’ Ø¨Ø®ÛŒØ± Ø¨Ø±Ø³Ø§Øª Ø¨Ø´Ø±Ø·ÛŒÚ©Û Ø¨Ø¹Ø¯ Ø¨Ø¹Ø¶ Ø¨ØºÛŒØ± Ø¨Ù„Ú©Û Ø¨Ù† Ø¨Ù†Ø§ Ø¨Ù†Ø§Ø¤ Ø¨Ù†Ø¯\n",
    " Ø¨Ú‘ÛŒ Ø¨Ú¾Ø± Ø¨Ú¾Ø±ÛŒÚº Ø¨Ú¾ÛŒ Ø¨ÛØ§Ø± Ø¨ÛØª Ø¨ÛØªØ± Ø¨ÛŒÚ¯Ù… ØªØ§Ú©Û ØªØ§ÛÙ… ØªØ¨ ØªØ¬Ú¾ ØªØ¬Ú¾ÛŒ ØªØ¬Ú¾Û’ ØªØ±Ø§ ØªØ±ÛŒ ØªÙ„Ú© ØªÙ… ØªÙ…Ø§Ù…\n",
    " ØªÙ…ÛØ§Ø±Ø§ ØªÙ…ÛØ§Ø±ÙˆÚº ØªÙ…ÛØ§Ø±ÛŒ ØªÙ…ÛØ§Ø±Û’ ØªÙ…ÛÛŒÚº ØªÙˆ ØªÚ© ØªÚ¾Ø§ ØªÚ¾ÛŒ ØªÚ¾ÛŒÚº ØªÚ¾Û’ ØªÛØ§Ø¦ÛŒ ØªÛŒØ±Ø§ ØªÛŒØ±ÛŒ ØªÛŒØ±Û’ ØªÛŒÙ† Ø¬Ø§ Ø¬Ø§Ø¤\n",
    " Ø¬Ø§Ø¦ÛŒÚº Ø¬Ø§Ø¦Û’ Ø¬Ø§ØªØ§ Ø¬Ø§ØªÛŒ Ø¬Ø§ØªÛ’ Ø¬Ø§Ù†ÛŒ Ø¬Ø§Ù†Û’ Ø¬Ø¨ Ø¬Ø¨Ú©Û Ø¬Ø¯Ú¾Ø± Ø¬Ø³ Ø¬Ø³Û’ Ø¬Ù† Ø¬Ù†Ø§Ø¨ Ø¬Ù†ÛÙˆÚº Ø¬Ù†ÛÛŒÚº Ø¬Ùˆ Ø¬ÛØ§Úº Ø¬ÛŒ\n",
    " Ø¬ÛŒØ³Ø§ Ø¬ÛŒØ³ÙˆÚº Ø¬ÛŒØ³ÛŒ Ø¬ÛŒØ³Û’ Ø¬ÛŒÙ¹Ú¾ Ø­Ø§Ù„Ø§Ù†Ú©Û Ø­Ø§Ù„Ø§Úº Ø­ØµÛ Ø­Ø¶Ø±Øª Ø®Ø§Ø·Ø± Ø®Ø§Ù„ÛŒ Ø®Ø¯Ø§ Ø®Ø²Ø§Úº Ø®ÙˆØ§Û Ø®ÙˆØ¨ Ø®ÙˆØ¯ Ø¯Ø§Ø¦ÛŒÚº Ø¯Ø±Ù…ÛŒØ§Ù†\n",
    " Ø¯Ø±ÛŒÚº Ø¯Ùˆ Ø¯ÙˆØ±Ø§Ù† Ø¯ÙˆØ³Ø±Ø§ Ø¯ÙˆØ³Ø±ÙˆÚº Ø¯ÙˆØ³Ø±ÛŒ Ø¯ÙˆØ´Ù†Ø¨Û Ø¯ÙˆÚº Ø¯Ú©Ú¾Ø§Ø¦ÛŒÚº Ø¯Ú¯Ù†Ø§ Ø¯ÛŒ Ø¯ÛŒØ¦Û’ Ø¯ÛŒØ§ Ø¯ÛŒØªØ§ Ø¯ÛŒØªÛŒ Ø¯ÛŒØªÛ’ Ø¯ÛŒØ± Ø¯ÛŒÙ†Ø§ Ø¯ÛŒÙ†ÛŒ\n",
    " Ø¯ÛŒÙ†Û’ Ø¯ÛŒÚ©Ú¾Ùˆ Ø¯ÛŒÚº Ø¯ÛŒÛ’ Ø¯Û’ Ø°Ø±ÛŒØ¹Û’ Ø±Ú©Ú¾Ø§ Ø±Ú©Ú¾ØªØ§ Ø±Ú©Ú¾ØªÛŒ Ø±Ú©Ú¾ØªÛ’ Ø±Ú©Ú¾Ù†Ø§ Ø±Ú©Ú¾Ù†ÛŒ Ø±Ú©Ú¾Ù†Û’ Ø±Ú©Ú¾Ùˆ Ø±Ú©Ú¾ÛŒ Ø±Ú©Ú¾Û’ Ø±Û Ø±ÛØ§\n",
    " Ø±ÛØªØ§ Ø±ÛØªÛŒ Ø±ÛØªÛ’ Ø±ÛÙ†Ø§ Ø±ÛÙ†ÛŒ Ø±ÛÙ†Û’ Ø±ÛÙˆ Ø±ÛÛŒ Ø±ÛÛŒÚº Ø±ÛÛ’ Ø³Ø§ØªÚ¾ Ø³Ø§Ù…Ù†Û’ Ø³Ø§Ú‘Ú¾Û’ Ø³Ø¨ Ø³Ø¨Ú¾ÛŒ Ø³Ø±Ø§Ø³Ø± Ø³Ù„Ø§Ù… Ø³Ù…ÛŒØª Ø³ÙˆØ§\n",
    " Ø³ÙˆØ§Ø¦Û’ Ø³Ú©Ø§ Ø³Ú©ØªØ§ Ø³Ú©ØªÛ’ Ø³Û Ø³ÛÛŒ Ø³ÛŒ Ø³Û’ Ø´Ø§Ù… Ø´Ø§ÛŒØ¯ Ø´Ú©Ø±ÛŒÛ ØµØ§Ø­Ø¨ ØµØ§Ø­Ø¨Û ØµØ±Ù Ø¶Ø±ÙˆØ± Ø·Ø±Ø­ Ø·Ø±Ù Ø·ÙˆØ±\n",
    " Ø¹Ù„Ø§ÙˆÛ Ø¹ÛŒÙ† ÙØ±ÙˆØ±ÛŒ ÙÙ‚Ø· ÙÙ„Ø§Úº ÙÛŒ Ù‚Ø¨Ù„ Ù‚Ø·Ø§ Ù„Ø¦Û’ Ù„Ø§Ø¦ÛŒ Ù„Ø§Ø¦Û’ Ù„Ø§ØªØ§ Ù„Ø§ØªÛŒ Ù„Ø§ØªÛ’ Ù„Ø§Ù†Ø§ Ù„Ø§Ù†ÛŒ Ù„Ø§Ù†Û’ Ù„Ø§ÛŒØ§ Ù„Ùˆ\n",
    " Ù„ÙˆØ¬ÛŒ Ù„ÙˆÚ¯ÙˆÚº Ù„Ú¯ Ù„Ú¯Ø§ Ù„Ú¯ØªØ§ Ù„Ú¯ØªÛŒ Ù„Ú¯ÛŒ Ù„Ú¯ÛŒÚº Ù„Ú¯Û’ Ù„ÛØ°Ø§ Ù„ÛŒ Ù„ÛŒØ§ Ù„ÛŒØªØ§ Ù„ÛŒØªÛŒ Ù„ÛŒØªÛ’ Ù„ÛŒÚ©Ù† Ù„ÛŒÚº Ù„ÛŒÛ’\n",
    " Ù„Û’ Ù…Ø§Ø³ÙˆØ§ Ù…Øª Ù…Ø¬Ú¾ Ù…Ø¬Ú¾ÛŒ Ù…Ø¬Ú¾Û’ Ù…Ø­ØªØ±Ù… Ù…Ø­ØªØ±Ù…Û Ù…Ø­ØªØ±Ù…ÛŒ Ù…Ø­Ø¶ Ù…Ø±Ø§ Ù…Ø±Ø­Ø¨Ø§ Ù…Ø±ÛŒ Ù…Ø±Û’ Ù…Ø²ÛŒØ¯ Ù…Ø³ Ù…Ø³Ø² Ù…Ø³Ù¹Ø± Ù…Ø·Ø§Ø¨Ù‚\n",
    " Ù…Ø·Ù„Ù‚ Ù…Ù„ Ù…Ù†Ù¹ Ù…Ù†Ù¹ÙˆÚº Ù…Ú©Ø±Ù…ÛŒ Ù…Ú¯Ø± Ù…Ú¯Ú¾Ø± Ù…ÛØ±Ø¨Ø§Ù†ÛŒ Ù…ÛŒØ±Ø§ Ù…ÛŒØ±ÙˆÚº Ù…ÛŒØ±ÛŒ Ù…ÛŒØ±Û’ Ù…ÛŒÚº Ù†Ø§ Ù†Ø²Ø¯ÛŒÚ© Ù†Ù…Ø§ Ù†Ùˆ Ù†ÙˆÙ…Ø¨Ø±\n",
    " Ù†Û Ù†ÛÛŒÚº Ù†ÛŒØ² Ù†ÛŒÚ†Û’ Ù†Û’ Ùˆ ÙˆØ§Ø± ÙˆØ§Ø³Ø·Û’ ÙˆØ§Ù‚Ø¹ÛŒ ÙˆØ§Ù„Ø§ ÙˆØ§Ù„ÙˆÚº ÙˆØ§Ù„ÛŒ ÙˆØ§Ù„Û’ ÙˆØ§Û ÙˆØ¬Û ÙˆØ±Ù†Û ÙˆØ¹Ù„ÛŒÚ©Ù… ÙˆØºÛŒØ±Û ÙˆÙ„Û’\n",
    " ÙˆÚ¯Ø±Ù†Û ÙˆÛ ÙˆÛØ§Úº ÙˆÛÛŒ ÙˆÛÛŒÚº ÙˆÛŒØ³Ø§ ÙˆÛŒØ³Û’ ÙˆÛŒÚº Ù¾Ø§Ø³ Ù¾Ø§ÛŒØ§ Ù¾Ø± Ù¾Ø³ Ù¾Ù„ÛŒØ² Ù¾ÙˆÙ† Ù¾ÙˆÙ†Ø§ Ù¾ÙˆÙ†ÛŒ Ù¾ÙˆÙ†Û’ Ù¾Ú¾Ø§Ú¯Ù†\n",
    " Ù¾Ú¾Ø± Ù¾Û Ù¾ÛØ± Ù¾ÛÙ„Ø§ Ù¾ÛÙ„ÛŒ Ù¾ÛÙ„Û’ Ù¾ÛŒØ± Ù¾ÛŒÚ†Ú¾Û’ Ú†Ø§ÛØ¦Û’ Ú†Ø§ÛØªÛ’ Ú†Ø§ÛÛŒØ¦Û’ Ú†Ø§ÛÛ’ Ú†Ù„Ø§ Ú†Ù„Ùˆ Ú†Ù„ÛŒÚº Ú†Ù„Û’ Ú†Ù†Ø§Ú†Û Ú†Ù†Ø¯ Ú†ÙˆÙ†Ú©Û\n",
    " Ú†ÙˆÚ¯Ù†ÛŒ Ú†Ú©ÛŒ Ú†Ú©ÛŒÚº Ú†Ú©Û’ Ú†ÛØ§Ø±Ø´Ù†Ø¨Û Ú†ÛŒØª ÚˆØ§Ù„Ù†Ø§ ÚˆØ§Ù„Ù†ÛŒ ÚˆØ§Ù„Ù†Û’ ÚˆØ§Ù„Û’ Ú©Ø¦Û’ Ú©Ø§ Ú©Ø§ØªÚ© Ú©Ø§Ø´ Ú©Ø¨ Ú©Ø¨Ú¾ÛŒ Ú©Ø¯Ú¾Ø± Ú©Ø±\n",
    " Ú©Ø±ØªØ§ Ú©Ø±ØªÛŒ Ú©Ø±ØªÛ’ Ú©Ø±Ù… Ú©Ø±Ù†Ø§ Ú©Ø±Ù†Û’ Ú©Ø±Ùˆ Ú©Ø±ÛŒÚº Ú©Ø±Û’ Ú©Ø³ Ú©Ø³ÛŒ Ú©Ø³Û’ Ú©Ù„ Ú©Ù… Ú©Ù† Ú©Ù†ÛÛŒÚº Ú©Ùˆ Ú©ÙˆØ¦ÛŒ Ú©ÙˆÙ†\n",
    " Ú©ÙˆÙ†Ø³Ø§ Ú©ÙˆÙ†Ø³Û’ Ú©Ú†Ú¾ Ú©Û Ú©ÛØ§ Ú©ÛØ§Úº Ú©ÛÛ Ú©ÛÛŒ Ú©ÛÛŒÚº Ú©ÛÛ’ Ú©ÛŒ Ú©ÛŒØ§ Ú©ÛŒØ³Ø§ Ú©ÛŒØ³Û’ Ú©ÛŒÙˆÙ†Ú©Ø± Ú©ÛŒÙˆÙ†Ú©Û Ú©ÛŒÙˆÚº Ú©ÛŒÛ’\n",
    " Ú©Û’ Ú¯Ø¦ÛŒ Ú¯Ø¦Û’ Ú¯Ø§ Ú¯Ø±Ù…Ø§ Ú¯Ø±Ù…ÛŒ Ú¯Ù†Ø§ Ú¯Ùˆ Ú¯ÙˆÛŒØ§ Ú¯Ú¾Ù†Ù¹Ø§ Ú¯Ú¾Ù†Ù¹ÙˆÚº Ú¯Ú¾Ù†Ù¹Û’ Ú¯ÛŒ Ú¯ÛŒØ§ ÛØ§Ø¦ÛŒÚº ÛØ§Ø¦Û’ ÛØ§Ú‘ ÛØ§Úº ÛØ±\n",
    " ÛØ±Ú†Ù†Ø¯ ÛØ±Ú¯Ø² ÛØ²Ø§Ø± ÛÙØªÛ ÛÙ… ÛÙ…Ø§Ø±Ø§ ÛÙ…Ø§Ø±ÛŒ ÛÙ…Ø§Ø±Û’ ÛÙ…ÛŒ ÛÙ…ÛŒÚº ÛÙˆ ÛÙˆØ¦ÛŒ ÛÙˆØ¦ÛŒÚº ÛÙˆØ¦Û’ ÛÙˆØ§ ÛÙˆØ¨ÛÙˆ ÛÙˆØªØ§ ÛÙˆØªÛŒ\n",
    " ÛÙˆØªÛŒÚº ÛÙˆØªÛ’ ÛÙˆÙ†Ø§ ÛÙˆÙ†Ú¯Û’ ÛÙˆÙ†ÛŒ ÛÙˆÙ†Û’ ÛÙˆÚº ÛÛŒ ÛÛŒÙ„Ùˆ ÛÛŒÚº ÛÛ’ ÛŒØ§ ÛŒØ§Øª ÛŒØ¹Ù†ÛŒ ÛŒÚ© ÛŒÛ ÛŒÛØ§Úº ÛŒÛÛŒ ÛŒÛÛŒÚº\n",
    "\n",
    "\n",
    "\"\"\".split())\n",
    "\n",
    "final_stopwords = set(stopwords_from_file + stopwords_from_csv)\n",
    "final_stopwords.update(stop_words) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment words found in stopwords: ['Ù†ÛÛŒÚº']\n"
     ]
    }
   ],
   "source": [
    "# checking if stopwords contain any sentiment words\n",
    "urdu_sentiment_words = [\"Ù†ÛÛŒÚº\", \"Ø¨Ø±Ø§\", \"Ø®ÙˆØ´\", \"Ø§Ú†Ú¾Ø§\"]\n",
    "found=[]\n",
    "for stopword in final_stopwords:\n",
    "    if stopword in urdu_sentiment_words:\n",
    "        found.append(stopword)\n",
    "\n",
    "if found:\n",
    "    print(\"Sentiment words found in stopwords:\", found)\n",
    "    final_stopwords.update(found)\n",
    "else:\n",
    "    print(\"No sentiment words found in stopwords.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "print(df[\"urdu_text\"].isnull().sum())\n",
    "df.dropna(subset=['urdu_text', 'is_sarcastic'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numbers Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(x):\n",
    "    return re.sub(r'\\d+', '', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"urdu_text\"]=df[\"urdu_text\"].apply(remove_numbers)\n",
    "# print(df[\"urdu_text\"][12])\n",
    "# print(remove_numbers(df[\"urdu_text\"][12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emojis Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"  \n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"  \n",
    "        u\"\\U000024C2-\\U0001F251\"  \n",
    "        u\"\\U0001F900-\\U0001F9FF\"  # additional emojis\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"urdu_text\"]=df[\"urdu_text\"].apply(remove_emoji)\n",
    "# print(df[\"urdu_text\"][0])\n",
    "# print(remove_emoji(df[\"urdu_text\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashtag and Mentions Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hash_sign(text):\n",
    "    return re.sub(r'#', '', text)  \n",
    "\n",
    "def remove_mentions(text):\n",
    "    return re.sub(r'@\\w+', '', text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ø¬Ø¨ Ú©ØªÛ’ Ø²ÛŒØ§Ø¯Û Ø¨Ú¾ÙˆÙ†Ú©Ù†Û’ Ù„Ú¯Û’ ØªÙˆ Ø§Ù† Ú©Û’ Ø¢Ú¯Û’ Ø±Ú©Ú¾Ù†Û’ Ú©ÛŒÙ„Ø¦Û’ ÛÚˆÛŒÙˆÚº Ú©ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ø¨Ú‘Ú¾Ø§ Ø¯ÙˆØ§Ù‚ÙˆØ§Ù„ Ú©Ø±Ø§Ø¦Ù… Ù…Ù†Ø³Ù¹Ø± Ø´ÙˆØ¨Ø§Ø² Ø´Ø±ÛŒÙ Ø¨Ø±Ø§Ø¯Ø± Ú¯ÙˆØ§Ù„Ù…Ù†ÚˆÛŒÙ„Ø§ Ù„Ù†Ø¯Ù† ÙˆØ§Ù„Û’ Ø³Û’ Ø§Ù‚ØªØ¨Ø§Ø³Ø§Ù…Ù¾ÙˆØ±Ù¹Úˆ_Ø­Ú©ÙˆÙ…Øª_Ù†Ø§Ù…Ù†Ø¸ÙˆØ± Ø§Ù…Ù¾ÙˆØ±Ù¹Úˆ_Ø¹Ø¯Ø§Ù„ØªÛŒÚº_Ù†Ø§Ù…Ù†Ø¸ÙˆØ±\n",
      " Ø¨ØºØ¶ Ú©Ùˆ Ú©ÛŒØ³Û’ Ø³Ø§Ø¦ÛŒÚˆ Ù¾Û Ø±Ú©Ú¾ÛŒÚºØŸ Ø§Ø¨Ùˆ Ø¬ÛÙ„ Ú©Ùˆ Ø¨Ú¾Ù„Ø§ Ø¬ÛÙ†Ù… Ù…ÛŒÚº ØªÙ†ÛØ§ Ú†Ú¾ÙˆÚ‘ Ø¯ÛŒÚºÛ” ØªÙˆÚ‘ Ø³Ø§ØªÚ¾ Ù†Ø¨Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’\n",
      "Sarcasm\n",
      " Ø¬Ø¨ Ú©ØªÛ’ Ø²ÛŒØ§Ø¯Û Ø¨Ú¾ÙˆÙ†Ú©Ù†Û’ Ù„Ú¯Û’ ØªÙˆ Ø§Ù† Ú©Û’ Ø¢Ú¯Û’ Ø±Ú©Ú¾Ù†Û’ Ú©ÛŒÙ„Ø¦Û’ ÛÚˆÛŒÙˆÚº Ú©ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ø¨Ú‘Ú¾Ø§ Ø¯ÙˆØ§Ù‚ÙˆØ§Ù„ Ú©Ø±Ø§Ø¦Ù… Ù…Ù†Ø³Ù¹Ø± Ø´ÙˆØ¨Ø§Ø² Ø´Ø±ÛŒÙ Ø¨Ø±Ø§Ø¯Ø± Ú¯ÙˆØ§Ù„Ù…Ù†ÚˆÛŒÙ„Ø§ Ù„Ù†Ø¯Ù† ÙˆØ§Ù„Û’ Ø³Û’ Ø§Ù‚ØªØ¨Ø§Ø³Ø§Ù…Ù¾ÙˆØ±Ù¹Úˆ_Ø­Ú©ÙˆÙ…Øª_Ù†Ø§Ù…Ù†Ø¸ÙˆØ± Ø§Ù…Ù¾ÙˆØ±Ù¹Úˆ_Ø¹Ø¯Ø§Ù„ØªÛŒÚº_Ù†Ø§Ù…Ù†Ø¸ÙˆØ±\n",
      " Ø¨ØºØ¶ Ú©Ùˆ Ú©ÛŒØ³Û’ Ø³Ø§Ø¦ÛŒÚˆ Ù¾Û Ø±Ú©Ú¾ÛŒÚºØŸ Ø§Ø¨Ùˆ Ø¬ÛÙ„ Ú©Ùˆ Ø¨Ú¾Ù„Ø§ Ø¬ÛÙ†Ù… Ù…ÛŒÚº ØªÙ†ÛØ§ Ú†Ú¾ÙˆÚ‘ Ø¯ÛŒÚºÛ” ØªÙˆÚ‘ Ø³Ø§ØªÚ¾ Ù†Ø¨Ú¾Ø§Ø¦ÛŒÚº Ú¯Û’\n",
      "Sarcasm\n"
     ]
    }
   ],
   "source": [
    "df[\"urdu_text\"]=df[\"urdu_text\"].apply(remove_hash_sign)\n",
    "print(df[\"urdu_text\"][5277])\n",
    "print(df[\"urdu_text\"][5612])\n",
    "df[\"urdu_text\"]=df[\"urdu_text\"].apply(remove_mentions)\n",
    "print(df[\"urdu_text\"][5277])\n",
    "print(df[\"urdu_text\"][5612])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URLs Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"urdu_text\"]=df[\"urdu_text\"].apply(remove_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove English Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_english_words(text):\n",
    "    return re.sub(r'\\b[a-zA-Z]+\\b', '', text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"urdu_text\"]=df[\"urdu_text\"].apply(remove_english_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "urdu_diacritics  = ['Ù', 'Ù°', 'Ù', 'Ù', 'Ù‹', 'Ù']\n",
    "\n",
    "def remove_diacritics(text):\n",
    "    for letter in text:\n",
    "    \n",
    "        if letter in urdu_diacritics:\n",
    "            text = text.replace(letter, '')\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"urdu_text\"]=df[\"urdu_text\"].apply(remove_diacritics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    # Defining the punctuation characters to remove\n",
    "    punct = 'Ø›Û”Ù«Ùª+=@#!ØŸØŒ)(}{\\'\"â€˜â€™â€œâ€``'\n",
    "    return text.translate(str.maketrans('', '', punct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"urdu_text\"]=df[\"urdu_text\"].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word not in final_stopwords:  \n",
    "            new_text.append(word)  \n",
    "    return \" \".join(new_text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø¨ÛØªØ±ÛŒÙ† Ú©ØªØ§Ø¨\n"
     ]
    }
   ],
   "source": [
    "cleaned_text = remove_stopwords(\"ÛŒÛ Ø§ÛŒÚ© Ø¨ÛØªØ±ÛŒÙ† Ú©ØªØ§Ø¨ ÛÛ’\")\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ù„ÛŒÙ†Û’ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ú©ÙˆØ¬ÛŒ Ú†Ø§ÛÛŒÛ’</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ Ø¢Úº</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ø§Ù¾ÙˆØ²ÛŒØ´Ù† Ú©Ø±Ø¯...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù¾Ø§Ø¦ÛŒÙ†</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ø¨Ú¾ÛŒØ³ ÚˆÛŒ Ø§ÛŒØ³ '' Ø­Ø§Ù…Ø¯ Ù…ÛŒØ±</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªØ¨Ø§Ø± Ù‚Ø§ØªÙ„ Ø§Ø¹ØªØ¨Ø§Ø±</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ø§Ù†Ø³Ø§Úº ØªÚ¾Ú©Ø§ Ø³ÙˆÚ†ÙˆÚº Ø³ÙØ± ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ø­Ø§Ù…Ø¯ Ù…ÛŒØ± ÙˆÛŒÙ„ÚˆÙ†</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ÛŒØ§Ø± ÙˆÚ†Ø§Ø±Û ÙˆÛŒÙ„Ø§ ÛÙˆÙ†Ø¯Ø§ Ø¢Ø±Û’ ÛÙˆÛŒØ§ ØªØ³ÛŒ ØªÛ’ Ù¾Ú©Û’ Ù†Ø¬ÙˆÙ…ÛŒ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ø³Ù…Ø¬Ú¾ØªÛ’ Ø³Ø§Ø±Ø§ Ù¾Ø§Ú©Ø³ØªØ§Ù† Ø¨ÛŒÙˆÙ‚ÙˆÙ Ú¾Û’</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           urdu_text  is_sarcastic\n",
       "0                         Ù„ÛŒÙ†Û’ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ú©ÙˆØ¬ÛŒ Ú†Ø§ÛÛŒÛ’           1.0\n",
       "1         Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ Ø¢Úº           1.0\n",
       "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ø§Ù¾ÙˆØ²ÛŒØ´Ù† Ú©Ø±Ø¯...           0.0\n",
       "3                                              Ù¾Ø§Ø¦ÛŒÙ†           0.0\n",
       "4            `` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ø¨Ú¾ÛŒØ³ ÚˆÛŒ Ø§ÛŒØ³ '' Ø­Ø§Ù…Ø¯ Ù…ÛŒØ±           1.0\n",
       "5                            Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªØ¨Ø§Ø± Ù‚Ø§ØªÙ„ Ø§Ø¹ØªØ¨Ø§Ø±           1.0\n",
       "6                           Ø§Ù†Ø³Ø§Úº ØªÚ¾Ú©Ø§ Ø³ÙˆÚ†ÙˆÚº Ø³ÙØ± ...           0.0\n",
       "7                                     Ø­Ø§Ù…Ø¯ Ù…ÛŒØ± ÙˆÛŒÙ„ÚˆÙ†           0.0\n",
       "8  ÛŒØ§Ø± ÙˆÚ†Ø§Ø±Û ÙˆÛŒÙ„Ø§ ÛÙˆÙ†Ø¯Ø§ Ø¢Ø±Û’ ÛÙˆÛŒØ§ ØªØ³ÛŒ ØªÛ’ Ù¾Ú©Û’ Ù†Ø¬ÙˆÙ…ÛŒ...           1.0\n",
       "9                      Ø³Ù…Ø¬Ú¾ØªÛ’ Ø³Ø§Ø±Ø§ Ù¾Ø§Ú©Ø³ØªØ§Ù† Ø¨ÛŒÙˆÙ‚ÙˆÙ Ú¾Û’           1.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['urdu_text'] = df['urdu_text'].apply(remove_stopwords)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Short Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_short_posts(text):\n",
    "    words = text.split()\n",
    "    return len(words) >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['urdu_text'].apply(filter_short_posts)\n",
    "df = df[mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ù„ÛŒÙ†Û’ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ú©ÙˆØ¬ÛŒ Ú†Ø§ÛÛŒÛ’</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ Ø¢Úº</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ø§Ù¾ÙˆØ²ÛŒØ´Ù† Ú©Ø±Ø¯...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ø¨Ú¾ÛŒØ³ ÚˆÛŒ Ø§ÛŒØ³  Ø­Ø§Ù…Ø¯ Ù…ÛŒØ±</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªØ¨Ø§Ø± Ù‚Ø§ØªÙ„ Ø§Ø¹ØªØ¨Ø§Ø±</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ø§Ù†Ø³Ø§Úº ØªÚ¾Ú©Ø§ Ø³ÙˆÚ†ÙˆÚº Ø³ÙØ± ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ø­Ø§Ù…Ø¯ Ù…ÛŒØ± ÙˆÛŒÙ„ÚˆÙ†</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ÛŒØ§Ø± ÙˆÚ†Ø§Ø±Û ÙˆÛŒÙ„Ø§ ÛÙˆÙ†Ø¯Ø§ Ø¢Ø±Û’ ÛÙˆÛŒØ§ ØªØ³ÛŒ ØªÛ’ Ù¾Ú©Û’ Ù†Ø¬ÙˆÙ…ÛŒ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ø³Ù…Ø¬Ú¾ØªÛ’ Ø³Ø§Ø±Ø§ Ù¾Ø§Ú©Ø³ØªØ§Ù† Ø¨ÛŒÙˆÙ‚ÙˆÙ Ú¾Û’</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ØªØ³ÛŒ Ù„Ú‘Ø§ÚºÙ”ÛŒ Ú©Ø±ÙˆØ§Ù†ÛŒ Ø³Ø§ÚˆÛŒ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ù¾Ø§Ø¦Ù† Ø¯ÙˆØ¨Ø§Ø±Û ÙØ§Ù„Ùˆ Ú©Ø±Ø¦ÛŒÛ’..</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ú©ØªÙ†ÛŒ Ù…ÛÙ†Ú¯Ø§Ø¦ÛŒ Ø§Ù„Ùˆ Ø¯ÙˆØ³Ùˆ Ø±ÙˆÙ¾Û’ Ø¯Ø±Ø¬Ù† Ú©Ø¯Ùˆ Ø±ÙˆÙ¾Û’ Ú¯Ø²</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ø¹Ø´Ù‚ Ø±Ø§Ø³ Ø¢Û“ Ø²Ø®Ù… Ú©Ú¾Ø§Ù¶ Ù…Ø³Ú©Ø±Ø§Ù¶</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ø®Ø§ØªÙ…_Ø§Ù„Ù†Ø¨ÛŒÛŒÙ†_Ù…Ø­Ù…Ø¯ Ø³ÙˆØ±Ø© Ø§Ù„Ù…Ø²Ù…Ù„ ØªØ±Ø¬Ù…Û Ø§Ù„Ù„Û Ø±Ø§Û Ù„...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ø¨Ø³ Ø¨ÛŒÚ†Ø§Ø±Û’ Ø¨ÛŒÙˆÛŒØ§Úº ÛÛŒÛ’ ØªÛŒØ³Ø±ÛŒ Ù¹Ø±Ø§Ø¦</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            urdu_text  is_sarcastic\n",
       "0                          Ù„ÛŒÙ†Û’ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ú©ÙˆØ¬ÛŒ Ú†Ø§ÛÛŒÛ’           1.0\n",
       "1          Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ Ø¢Úº           1.0\n",
       "2   Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ø§Ù¾ÙˆØ²ÛŒØ´Ù† Ú©Ø±Ø¯...           0.0\n",
       "3                  Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ø¨Ú¾ÛŒØ³ ÚˆÛŒ Ø§ÛŒØ³  Ø­Ø§Ù…Ø¯ Ù…ÛŒØ±           1.0\n",
       "4                             Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªØ¨Ø§Ø± Ù‚Ø§ØªÙ„ Ø§Ø¹ØªØ¨Ø§Ø±           1.0\n",
       "5                            Ø§Ù†Ø³Ø§Úº ØªÚ¾Ú©Ø§ Ø³ÙˆÚ†ÙˆÚº Ø³ÙØ± ...           0.0\n",
       "6                                      Ø­Ø§Ù…Ø¯ Ù…ÛŒØ± ÙˆÛŒÙ„ÚˆÙ†           0.0\n",
       "7   ÛŒØ§Ø± ÙˆÚ†Ø§Ø±Û ÙˆÛŒÙ„Ø§ ÛÙˆÙ†Ø¯Ø§ Ø¢Ø±Û’ ÛÙˆÛŒØ§ ØªØ³ÛŒ ØªÛ’ Ù¾Ú©Û’ Ù†Ø¬ÙˆÙ…ÛŒ...           1.0\n",
       "8                       Ø³Ù…Ø¬Ú¾ØªÛ’ Ø³Ø§Ø±Ø§ Ù¾Ø§Ú©Ø³ØªØ§Ù† Ø¨ÛŒÙˆÙ‚ÙˆÙ Ú¾Û’           1.0\n",
       "9                              ØªØ³ÛŒ Ù„Ú‘Ø§ÚºÙ”ÛŒ Ú©Ø±ÙˆØ§Ù†ÛŒ Ø³Ø§ÚˆÛŒ           0.0\n",
       "10                           Ù¾Ø§Ø¦Ù† Ø¯ÙˆØ¨Ø§Ø±Û ÙØ§Ù„Ùˆ Ú©Ø±Ø¦ÛŒÛ’..           0.0\n",
       "11        Ú©ØªÙ†ÛŒ Ù…ÛÙ†Ú¯Ø§Ø¦ÛŒ Ø§Ù„Ùˆ Ø¯ÙˆØ³Ùˆ Ø±ÙˆÙ¾Û’ Ø¯Ø±Ø¬Ù† Ú©Ø¯Ùˆ Ø±ÙˆÙ¾Û’ Ú¯Ø²           1.0\n",
       "12                         Ø¹Ø´Ù‚ Ø±Ø§Ø³ Ø¢Û“ Ø²Ø®Ù… Ú©Ú¾Ø§Ù¶ Ù…Ø³Ú©Ø±Ø§Ù¶           1.0\n",
       "13  Ø®Ø§ØªÙ…_Ø§Ù„Ù†Ø¨ÛŒÛŒÙ†_Ù…Ø­Ù…Ø¯ Ø³ÙˆØ±Ø© Ø§Ù„Ù…Ø²Ù…Ù„ ØªØ±Ø¬Ù…Û Ø§Ù„Ù„Û Ø±Ø§Û Ù„...           0.0\n",
       "14                    Ø¨Ø³ Ø¨ÛŒÚ†Ø§Ø±Û’ Ø¨ÛŒÙˆÛŒØ§Úº ÛÛŒÛ’ ØªÛŒØ³Ø±ÛŒ Ù¹Ø±Ø§Ø¦           1.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
